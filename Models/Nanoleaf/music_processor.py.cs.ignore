
using pyaudio;

using librosa;

using np = numpy;

using argparse;

using socket;

using sys;

using threading;

using sleep = time.sleep;

using time = time.time;

using StrictVersion = distutils.version.StrictVersion;

using input = builtins.input;

using System.Collections.Generic;

using System;

using System.Linq;

public static class music_processor {
    
    public static object pyaudio_lock = threading.Lock();
    
    public static object keypress_lock = threading.Lock();
    
    public static bool stop_pyaudio_thread = false;
    
    public static object data_buffer = new List<object>();
    
    public static bool data_buffer_updated = false;
    
    public static int sample_rate = 0;
    
    public static bool stop_loop = false;
    
    
    public class PyAudioThread
        : threading.Thread {
        
        public object input_format;
        
        public object input_samples;
        
        public PyAudioThread(object input_samples, object input_format) {
            this.input_format = input_format;
            this.input_samples = input_samples;
        }
        
        public virtual object run() {
            // create pyaudio object
            var pa = pyaudio.PyAudio();
            // get default host/input device info dicts
            try {
                var host_api_info = pa.get_default_host_api_info();
                var default_input_device_info = pa.get_default_input_device_info();
            } catch (IOError) {
                Console.WriteLine("Input audio device not found, terminating ...");
                pa.terminate();
                sys.exit();
            }
            var default_input_sample_rate = default_input_device_info["defaultSampleRate"];
            var default_low_input_latency = default_input_device_info["defaultLowInputLatency"];
            var default_high_input_latency = default_input_device_info["defaultHighInputLatency"];
            var default_max_input_channels = default_input_device_info["maxInputChannels"];
            Console.WriteLine("default inputs: sample rate {}, latency low {:.4f}, latency high {:.4f}, channels {}".format(default_input_sample_rate, default_low_input_latency, default_high_input_latency, default_max_input_channels));
            pyaudio_lock.acquire();
            sample_rate = default_input_sample_rate;
            pyaudio_lock.release();
            var stream = pa.open(rate: Convert.ToInt32(sample_rate), channels: 1, format: this.input_format, input: true, frames_per_buffer: this.input_samples, stream_callback: PyAudioThread.input_callback);
            stream.start_stream();
            while (!stop_pyaudio_thread) {
                sleep(0.1);
            }
            stream.stop_stream();
            stream.close();
            // terminate pyaudio object
            pa.terminate();
        }
        
        [staticmethod]
        public static object input_callback(object in_data, object frame_count, object time_info, object status) {
            pyaudio_lock.acquire();
            data_buffer = in_data;
            data_buffer_updated = true;
            pyaudio_lock.release();
            return Tuple.Create(null, pyaudio.paContinue);
        }
    }
    
    // 
    // 
    //     :param mag:     numpy array of magnitudes of frequency bins
    //     :param scalar:      previous scalar
    //     :param min_scalar:  minimum scalar
    //     :return:            updated scalar
    //     
    public static object update_magnitude_scaling(object mag, object scalar, object min_scalar) {
        var max_mag = np.max(mag);
        var mag_diff = max_mag - scalar;
        var updated_scalar = scalar + 0.02 * mag_diff;
        if (scalar < min_scalar) {
            updated_scalar = min_scalar;
        }
        // print("{} ({})".format(updated_scalar, max_mag))
        return updated_scalar;
    }
    
    public static object visualizer(object data_in) {
        var scalar = 5;
        var hi_limit = 100;
        var value = np.sum(Math.Pow(np.abs(data_in), 2)) * scalar;
        if (value > hi_limit) {
            value = hi_limit;
        }
        value = Convert.ToInt32(value);
        // back to front of row
        sys.stdout.write("\r");
        // write "|" followed by spaces
        foreach (var i in Enumerable.Range(0, Convert.ToInt32(Math.Ceiling(Convert.ToDouble(value - 0) / 1))).Select(_x_1 => 0 + _x_1 * 1)) {
            sys.stdout.write("|");
        }
        foreach (var i in Enumerable.Range(0, Convert.ToInt32(Math.Ceiling(Convert.ToDouble(hi_limit - value) / 1))).Select(_x_2 => value + _x_2 * 1)) {
            sys.stdout.write(" ");
        }
        sys.stdout.write("\n");
        // flush output
        sys.stdout.flush();
    }
    
    public static object check_min_versions() {
        var ret = true;
        // pyaudio
        var vers_required = "0.2.7";
        var vers_current = pyaudio.@__version__;
        if (StrictVersion(vers_current) < StrictVersion(vers_required)) {
            Console.WriteLine("Error: minimum pyaudio vers: {}, current vers {}".format(vers_required, vers_current));
            ret = false;
        }
        // librosa
        vers_required = "0.4.3";
        vers_current = librosa.@__version__;
        if (StrictVersion(vers_current) < StrictVersion(vers_required)) {
            Console.WriteLine("Error: minimum librosa vers: {}, current vers {}".format(vers_required, vers_current));
            ret = false;
        }
        // numpy
        vers_required = "1.9.0";
        vers_current = np.@__version__;
        if (StrictVersion(vers_current) < StrictVersion(vers_required)) {
            Console.WriteLine("Error: minimum numpy vers: {}, current vers {}".format(vers_required, vers_current));
            ret = false;
        }
        return ret;
    }
    
    public static object get_output_fft_bins(object fft_mag, object n_out) {
        var n_in = fft_mag.Count;
        var step_size = Convert.ToInt32(n_in / n_out);
        var fft_out = np.zeros(n_out);
        var n_filled = 0;
        var i = 0;
        while (n_filled < n_out) {
            var acc = np.sum(fft_mag[i::min((i  +  step_size),n_in)]);
            i += step_size;
            // saturate to 8-bit unsigned
            if (acc > 255) {
                acc = 255;
            }
            fft_out[n_filled] = acc;
            n_filled += 1;
        }
        return fft_out[0::n_out];
    }
    
    public static object process_music_data(
        object data_in,
        object is_fft,
        object is_mel,
        object n_out_bins,
        object n_fft,
        object n_mel,
        object is_energy,
        object is_visual) {
        object fft_output;
        object fft_data_mag;
        object energy_output;
        // length is len(data_in)/4
        var data_np = np.fromstring(data_in, "Float32");
        // visualizer
        if (is_visual) {
            visualizer(data_np);
        }
        // energy
        if (is_energy) {
            var energy = Math.Pow(np.abs(data_np), 2);
            energy = energy.sum();
            energy *= Math.Pow(2, 5);
            energy_output = energy.astype(np.uint16);
        } else {
            energy_output = np.zeros(2).astype(np.uint16);
        }
        // fft or mel
        if (is_fft || is_mel) {
            // down-sample by 4, with filtering, energy not scaled
            data_np = librosa.resample(data_np, sample_rate, sample_rate / 4, res_type: "kaiser_fast");
            // short time fft over n_fft samples
            var fft_data = librosa.stft(data_np, n_fft, hop_length: n_fft, center: false);
            // calculate FFT or Mel
            if (is_fft) {
                fft_data_mag = Math.Pow(np.abs(fft_data[0::(n_fft  //  2)]), 2);
                fft_data_mag *= Math.Pow(2, 3);
                fft_output = get_output_fft_bins(fft_data_mag, n_out_bins);
            } else {
                fft_data_mag = Math.Pow(np.abs(fft_data), 2);
                fft_data_mag *= Math.Pow(2, 2);
                var mel_data = librosa.feature.melspectrogram(S: fft_data_mag, sr: sample_rate / 4, n_mels: n_mel);
                fft_output = get_output_fft_bins(mel_data, n_out_bins);
            }
            // output uint8_t
            fft_output = fft_output.astype(np.uint8);
        } else {
            fft_output = np.zeros(n_out_bins).astype(np.uint8);
        }
        return Tuple.Create(fft_output, energy_output);
    }
    
    public static int input_samples = Math.Pow(2, 11);
    
    public static object input_format = pyaudio.paFloat32;
    
    public static int min_delay = 50;
    
    public static int n_fft = 512;
    
    public static int n_mel = 26;
    
    public static string udp_host = "127.0.0.1";
    
    public static int udp_port = 27182;
    
    public static int sound_feature_udp_port = 27184;
    
    static music_processor() {
        exit(1);
        parser.add_argument("--viz", help: "turn on simple visualizer, please limit use to setup and debug", action: "store_true");
        udp_socket.bind((udp_host, sound_feature_udp_port));
        udp_socket.close();
        pa_thread.start();
        sleep(1);
        kp_thread.start();
        pyaudio_lock.acquire();
        pyaudio_lock.release();
        (fft, energy) = process_music_data(data, is_fft, is_mel, n_bins_out, n_fft, n_mel, is_energy, visualize);
        sleep(sleepTime / 1000.0);
        udp_socket.sendto(message, (udp_host, udp_port));
        keypress_lock.acquire();
        keypress_lock.release();
        pa_thread.join();
        kp_thread.join();
    }
    
    public static object parser = argparse.ArgumentParser(description: "Music processing and streaming script for the Nanoleaf Rhythm SDK");
    
    public static object args = parser.parse_args();
    
    public static object visualize = args.viz;
    
    public static object udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM);
    
    public static object from_host = addr[0];
    
    public static object tokens = packet.split();
    
    public static int is_fft = Convert.ToInt32(tokens[0]);
    
    public static int n_bins_out = Convert.ToInt32(tokens[1]);
    
    public static int is_energy = Convert.ToInt32(tokens[2]);
    
    public static int is_mel = Convert.ToInt32(tokens[3]);
    
    public static int n_bins_out = n_mel;
    
    public static bool is_fft = false;
    
    public static PyAudioThread pa_thread = new PyAudioThread(input_samples, input_format);
    
    public static object udp_socket = socket.socket(socket.AF_INET, socket.SOCK_DGRAM);
    
    public static List<object> data = new List<object>();
    
    public static bool data_updated = false;
    
    public static bool stop = false;
    
    public static KeyPressThread kp_thread = new KeyPressThread();
    
    public static int startTime = time();
    
    public static bool data_updated = data_buffer_updated;
    
    public static object data = data_buffer;
    
    public static bool data_buffer_updated = false;
    
    public static int stopTime = time();
    
    public static int elapsedTime = (stopTime - startTime) * 1000;
    
    public static int sleepTime = min_delay - elapsedTime;
    
    public static object message = fft.tobytes() + energy.tobytes();
    
    public static int startTime = time();
    
    public static bool stop = stop_loop;
    
    public static bool stop_pyaudio_thread = true;
}
